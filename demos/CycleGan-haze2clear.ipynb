{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autorelxoad\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms as T\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "from gan import models, build_cycle_gan_trainer, kl_cycle_gan_loss_step\n",
    "from utils.benchmark import train\n",
    "from utils.display import display_images\n",
    "from utils.checkpoints import load_checkpoint\n",
    "from utils.datasets import DomainDataset\n",
    "from __datasets__ import ITSDataset, DenseHazeCVPR2019Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f2c53d54bc6b0f5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config = models.CycleGanConfig(\n",
    "    \"../../pytorch/datasets/celeb-a\",\n",
    "    \"CycleGan-haze2clear\",\n",
    "\n",
    "    batch_size=8,\n",
    "    norm=nn.InstanceNorm2d,\n",
    "    writer=True,\n",
    "    lr=2e-4,\n",
    "    p=0,\n",
    "\n",
    "    inp_channels=3,\n",
    "    hidden_channels=64,\n",
    "    out_channels=3,\n",
    "    downsample=3,\n",
    "    residuals=7,\n",
    "    n=0,\n",
    "    blocks=(64, 128, 256, 512),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af0570be40919ab"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ds = DomainDataset(\n",
    "    ITSDataset(DIR=\"../../pytorch/datasets/its\", SET=\"hazy\", download=True, sub_sample=0.1,\n",
    "               image_transform=T.Compose([\n",
    "                   T.Resize((64, 64)),\n",
    "                   T.ToTensor(),\n",
    "                   T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                   lambda x: x.to(config.device),\n",
    "               ])),\n",
    "    ITSDataset(DIR=\"../../pytorch/datasets/its\", SET=\"clear\", download=True, sub_sample=0.1,\n",
    "               image_transform=T.Compose([\n",
    "                   T.Resize((64, 64)),\n",
    "                   T.ToTensor(),\n",
    "                   T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                   lambda x: x.to(config.device),\n",
    "               ])),\n",
    ")\n",
    "len(ds), type(ds[0:1])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14fc79060f1c104d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generatorA, generatorB, discriminatorA, discriminatorB = models.build_CycleGan(config)\n",
    "optimizerG = optim.Adam(list(generatorA.parameters()) + list(generatorB.parameters()), lr=config.lr, betas=config.betas)\n",
    "optimizerD = optim.Adam(list(discriminatorA.parameters()) + list(discriminatorB.parameters()), lr=config.lr,\n",
    "                        betas=config.betas)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54d57c0b732245b9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if input(\"Load Model[y|n]?> \").lower() == \"y\":\n",
    "    others = load_checkpoint(\n",
    "        input(\"path?> \"),\n",
    "        {\n",
    "            \"generatorA\": generatorA,\n",
    "            \"generatorB\": generatorB,\n",
    "            \"discriminatorA\": discriminatorA,\n",
    "            \"discriminatorB\": discriminatorB\n",
    "        },\n",
    "        {\n",
    "            \"optimizerG\": optimizerG,\n",
    "            \"optimizerD\": optimizerD,\n",
    "        }\n",
    "    )\n",
    "    step_offset = others[\"step\"]\n",
    "else:\n",
    "    step_offset = 0\n",
    "step_offset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2362798237ae5ea9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def data_extractor(DATA):\n",
    "    realA, realB = DATA[\"domain_0\"][\"image\"], DATA[\"domain_1\"][\"image\"]\n",
    "    return realA, realB\n",
    "\n",
    "\n",
    "fixed_inp = ds[0:9][\"domain_0\"][\"image\"], ds[0:9][\"domain_1\"][\"image\"]\n",
    "trainer = build_cycle_gan_trainer(\n",
    "    generatorA, generatorB, discriminatorA, discriminatorB,\n",
    "    optimizerG, optimizerD,\n",
    "    kl_cycle_gan_loss_step,\n",
    "    data_extractor,\n",
    "    config.writer, 100, fixed_inp,\n",
    "    save_path=None, save_period=500 * config.batch_size\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a799318fb0d73"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print((fake := generatorA(fixed_inp[0])).cpu().shape, discriminatorA(fake).shape)\n",
    "print((fake := generatorB(fixed_inp[1])).cpu().shape, discriminatorB(fake).shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3fdba940fba992d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generatorA = generatorA.train()\n",
    "generatorB = generatorB.train()\n",
    "discriminatorA = discriminatorA.train()\n",
    "discriminatorB = discriminatorB.train()\n",
    "step_offset = train(\n",
    "    trainer, ds,\n",
    "    ne=1, bs=config.batch_size,\n",
    "    step_offset=step_offset,\n",
    ")\n",
    "step_offset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76689d10b45db62e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "generatorA = generatorA.eval()\n",
    "generatorB = generatorB.eval()\n",
    "discriminatorA = discriminatorA.eval()\n",
    "discriminatorB = discriminatorB.eval()\n",
    "with torch.inference_mode():\n",
    "    realA, realB = fixed_inp\n",
    "    fakeA, fakeB = generatorA(realB), generatorB(realA)\n",
    "    backA, backB = generatorB(fakeA), generatorA(fakeB)\n",
    "    sameA, sameB = generatorA(realA), generatorB(realB)\n",
    "    doubleA, doubleB = generatorA(fakeA), generatorB(fakeB)\n",
    "    gridA = make_grid(torch.cat([realA, fakeB, backB, sameA, doubleA], dim=0), nrow=len(realA), normalize=True)\n",
    "    gridB = make_grid(torch.cat([realB, fakeA, backA, sameB, doubleB], dim=0), nrow=len(realB), normalize=True)\n",
    "display_images(torch.stack([gridA, gridB]).cpu().permute(0, 2, 3, 1))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ca6e485fa515035"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save_image(gridA, \"gridA.png\")\n",
    "save_image(gridB, \"gridB.png\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74ccb70f9a63a8ef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generatorA"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2801e0bdd682546a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ad40aefebc957d7b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
